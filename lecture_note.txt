[Lecture 1]
---------------------------------------- 3 ----------------------------------------
As a result -> amount of visual data is growing
*statistic* cisco: by 2017, roughly 80% of traffic on the internet -> video

Design algorithms to utilize visual data
- Hard to understand -> DARK MATTER of the internet

*statistic* Youtube: every sec. of real time 5 hours video uploaded
- Can't deal with it manually

---------------------------------------- 4 ----------------------------------------
- Visual data: complex -> huge learning parameters -> not enough data -> overfit
IMAGENET: 22K categories and 14M images 3 years work -> biggest in 2009
Amazon -> help: sort, clean and label

Challenge: 1431167 images and 1000 classes -> if top 5 labels include correct then success

---------------------------------------- 5 ----------------------------------------
start date 2010
why FCs are bad?
2011 to 2012 -> CNN emergence: ~10% drop in error
Human: 5.1 -> phd candidate not a normal guy

---------------------------------------- 6 ----------------------------------------
[Lecture 5]
First strong result: Alexnet 2012
step back ...
Hubel and wiesel: 1959 1962 1968 cats visual cortex
	simple cells: response to light orientation
	complex cells: response to light orientation and movement
	hypercomplex cells: response to movement with an end point


Gradient based learning: document recognition(zipcode) -> LeNet 1998
architecture:	
	conv
	pool
	conv
	pool
	FC
	FC
	output
- can't be scaled to complex data

---------------------------------------- 7 ----------------------------------------
AlexNet: 2012
first use of convNet -> biggest error change
taking advantage of large dataset
parallel computing with gpu

---------------------------------------- 8 ----------------------------------------
convolutional layer:
+ preserve spatial structure ...
weights are formed as small filters sliding over the input [slightly different from real conv]
depth of filter corresponds to number of input channels
stack filters to shape depth of output

---------------------------------------- 9 ----------------------------------------
first layers: low level features: edged
mid layers: corners
last layers: complex features: eyes
natural way...

-------------------------------------- 10-14 --------------------------------------
what is stride?
7*7 with 3*3 filter and stride 3 -> 1 padding
preserve size of image -> "same" convolution

---------------------------------------- 15 ----------------------------------------
trend: number of filters power of 2
	   filter size 3, 5, 7, ...
1*1 filter makes sense? yes, changes depth (downsample of d)
receptive field -> effective receptive field ...

---------------------------------------- 16 ----------------------------------------
pooling: downsample of h, w
avg, max, ...
+ makes features bold
trend: 2*2 with stride 2

---------------------------------------- 17 ----------------------------------------
we need FC for classification
reason on top of spatial features

---------------------------------------- 18 ----------------------------------------
[Lecture 9]

AlexNet: 2012 winner
architecture:
	227 * 227 * 3 input
	conv1 96 11*11 stride 4 pad 0
	maxpool1 3*3 stride 2
	norm1
	conv2 256 5*5 stride 1 pad 2
	maxpool2 384 3*3 stride 2
	norm2
	conv3 384 3*3 stride 1 pad 1
	conv4 384 3*3 stride 1 pad 1
	conv5 256 3*3 stride 1 pad 1
	maxpool2 3*3 stride 2
	FC6 4096
	FC7 4096
	FC8 1000

first use of relu
training needs more than 3 GB -> two GPUs
GPUs communicate through some layers

---------------------------------------- 19 ----------------------------------------
2013 winner ZFNet -> tuning AlexNet hyper parameters
conv1: 11*11 stride 4 -> 7*7 stride 2
conv3, 4, 5: 384, 384, 256 filters -> 512, 1024, 512

---------------------------------------- 20 ----------------------------------------
2014 winner: googleNet but VGG is interesting too.
oxford
+ Deeper Networks with smaller filters
	16-19 layers
	only conv 3*3 stride1 1
	max pool 2*2 stride 1
+ why?
	effective receptive field is the same:
		3 3*3 stride 1 = 7*7 conv
		fewer parameters: 3 3^2 c^2 < 7^2 c^2

- 96MB/image for forward (*2 for bwd)
- total parameters: 138M, FCs weights: 123.6M
- most of memory used in first conv layers

---------------------------------------- 22 ----------------------------------------
googleNet
+ computation efficiency
+ 22 layers
+ inception module ... detail

+ no FCs
+ only 5M parameters
+ 12x less than AlexNet

- naive implementation:
	- 854M ops -> 358M: using bottleneck layer -> project feature map
	- maintain dimensions -> computation complexity -> 1*1 conv to control channels

+ bottlenecks located beside and after maxpool
+ last layer is result concatenation
+ auxiliary classification outputs to inject Gradient (vanish)

---------------------------------------- 24 ----------------------------------------
2015 winner: resNet
+ 152 layers
+ won all contests in 2015
? getting deeper in plain CNN: error gets worse
	- it does not overfit -> both train and test error are bad 
	+ optimization problem with large Networks 
+ identity mapping and weights of a shallow Network -> 
	working at least as well as shallow network 

+ adding residual mapping -> the model learns solution -> skip some layers
+ H(x) = F(x) + x
+ double the channels but downsample using stride 2
+ using bottleneck like googleNet

training:
	sgd + momentum
	learning rate: 0.1 decay by 10
	weight decay 1e-5
	no dropout

---------------------------------------- 26 ----------------------------------------
[Lecture 11]
so far: image classification
more fancier -> classification + localization

---------------------------------------- 27 ----------------------------------------
+ we know ahead of time: we have only 1 object of interest
+ for box: treat localization as a regression problem

---------------------------------------- 28 ----------------------------------------
same idea of predicting fix number of positions in the image -> pose estimation.

---------------------------------------- 29 ----------------------------------------
core problem in computer vision
we don't know the number of objects

---------------------------------------- 31 ----------------------------------------
how do we choose the crops??
	- any number of objects
	- any location 
	- any size
	- any aspect ratio

applying them to cnn -> computationally intractable
+ instead: region proposals using other computer vision approaches (image processing)
+ selective search: 2 sec -> 2000 proposals
+ high recall

---------------------------------------- 32 ----------------------------------------
rcnn
- different RoI size -> warp images
svm -> classify + Bbox reg: correct the boundings
- fixed number of region proposals 2000 -> not able to learning
- super slow train and test

---------------------------------------- 33 ----------------------------------------
fast rcnn
+ learnable RoI 
+ conv5 -> complex features: eye, nose ....
+ RoI pooling layer: warp -> cropping from feature map instead of picture:
	eye + nose = face (so advanced -> simplify)

- Actually there is a fix method to extract RoI from feature map
	-> slow (2 sec in test)


---------------------------------------- 34 ----------------------------------------
10x faster to train: sharing computation between different feature maps
- runtime dominated by region proposals (bottleneck)

---------------------------------------- 35 ----------------------------------------
- replace fix method with RPN (region proposals network)
training:
	+ a threshold of overlap of proposal with ground truth images we have (advanced)
+ can be generalized to different problems: we can train RoI part

---------------------------------------- 36 ----------------------------------------
region based detection -> accurate but slow (RCNN)

---------------------------------------- 37 ----------------------------------------
alternative: all feed forward in a single pass: YOLO, SSD
+ independent processing for each potential regions ->  
	treat the problem as a big regression problem and 
	predict all of objects at once using a big CNN

+ grid cells: 7*7
+ base bounding boxes: more than 3

predict:
	+ offset off the bounding box -> true location
	+ classification score
